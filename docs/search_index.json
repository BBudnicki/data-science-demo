[["index.html", "Data Science Demo Introduction", " Data Science Demo Brandon Budnicki 2022-03-22 Introduction This R Bookdown website is my final project for the Introduction to Data Science Course ESS 580A7. I took this class in the Spring semester of 2022 as part of my candidacy in the Ecosystem Science &amp; Sustainability (ESS) PHD program at Colorado State University. "],["poudre-river-interactive-graph.html", "Chapter 1 Poudre River Interactive Graph 1.1 Methods 1.2 SiteDescription 1.3 Data Acquisition 1.4 Interactive Plot 1.5 Cameron Peak Fire", " Chapter 1 Poudre River Interactive Graph The Poudre river goes through northern Colorado through Fort Collins. By graphing the flow rate over time we can spot annual patterns &amp; sever weather events. Discharge data is downloaded by the dataRetrieval R package from the NWIS web service waterservices.usgs.gov 1.1 Methods The Poudre River at Lincoln Bridge is: Downstream of only a little bit of urban stormwater Near Odell Brewing CO Near an open space area and the Poudre River Trail Downstream of many agricultral diversions 1.2 SiteDescription 1.3 Data Acquisition q &lt;- readNWISdv( siteNumbers = &#39;06752260&#39;, parameterCd = &#39;00060&#39;, startDate = &#39;2017-01-01&#39;, endDate = &#39;2022-01-01&#39; ) %&gt;% rename(q = &#39;X_00060_00003&#39;) q_xts &lt;- xts(q$q, order.by = q$Date) 1.4 Interactive Plot series &lt;- cbind(points = q_xts) dygraph(series, main = &quot;Discharge in the Poudre River&quot;) %&gt;% dySeries(&quot;points&quot;, label = &quot;7 Day Averae&quot;, drawPoints = TRUE, pointSize = 3) %&gt;% dyAnnotation(&quot;2018-7-24&quot;, text = &quot;C&quot;, tooltip = &quot;Peak discharge&quot;) %&gt;% dyAnnotation(&quot;2018-7-22&quot;, text = &quot;B&quot;, tooltip = &quot;Larimer County lifts evacuation orders&quot;) %&gt;% dyAnnotation(&quot;2018-7-21&quot;, text = &quot;A&quot;, tooltip = &quot;Larimer County officials closed the Poudre River for all uses&quot;) %&gt;% dyRoller(rollPeriod = 1) %&gt;% dyRangeSelector(dateWindow = c(&quot;2018-07-01&quot;, &quot;2018-8-01&quot;)) %&gt;% dyAxis(&quot;y&quot;, label = &quot;Discharge (cfs)&quot;) Figure 1.1: Discharge in the Poudre River at the Lincoln Bride in Fort Collins, CO 1.5 Cameron Peak Fire Burn scars caused by the Cameron peak fire lead to dangerous discharge within the Poudre River on July 21st 2018 (Label A 1.1). Larimer County officials closed the Poudre River for all use and issued evacuation orders, finally reopening on July 22nd (Label B 1.1). These flood warnings were issued and then lifted before the peak discharge from this rainfall event on July 24th (Label C 1.1). "],["hayman-fire-google-earth-engine.html", "Chapter 2 Hayman Fire Google Earth Engine 2.1 NDVI over time 2.2 Correlation between NDVI &amp; NDMI 2.3 Snow and Vegitation 2.4 Greenest Month 2.5 Snowiest Month", " Chapter 2 Hayman Fire Google Earth Engine The Hayman Fire occurred June 8,2002 and was at the time the largest recorded wildfire in Colorado. By using Google Earth Engine to download remote sensing data, we can look at the impact the wildfire had on vegetation. Normalized Difference Vegetation Index (NDVI) Normalized Difference Snow Index (NDSI) Normalized Difference Moisture Index (NDMI) 2.1 NDVI over time There was a clear decrease in NDVI from pre to post burn at Site 2. Site 1 also saw a decrease, albeit quite a bit smaller. Figure 2.1: NDVI over time 2.2 Correlation between NDVI &amp; NDMI Exploring the correlation between NDVI &amp; NDMI looking at the summer months we can see that as surface moisture increases, vegetation increases. Site 2 saw a decrease in surface moisture and vegetation following the same ratio between NDVI and NDMI. Figure 2.2: Impact of surface moisture on vegatitation 2.3 Snow and Vegitation Looking at the previous years snow cover, we show little if any influence on vegetation growth the following summer. Both for the Site 1 &amp; Site 2 pre burn. There is a clear shift in vegetation due to the impacts of burned areas 2.3 from site 2 pre burn to site 2 post burn. The snow cover had lower maximums during this time. This could be due to darker surfaces but also could be due to outside factors such as warmer winters. Based on the sample size it is difficult to tell from this data. Figure 2.3: Impact of snow cover on vegatative growth 2.4 Greenest Month August is the greenest month based on the Normalized Difference Vegetation Index. This holds true for both unburned &amp; burned sites. Figure 2.4: Vegitation (NDVI) by Month 2.5 Snowiest Month Snow cover was greatest in January &amp; February. Site 1 had greater cover than site 2. This can be used as a proxy for snow fall, but is not a direct measurement as the freeze thaw cycle impacts the cover. Interestingly the snow cover post burn at site 2 was less than pre burn. This might be caused by a number of factors related or not related to the burn as theorized in 2.3. Figure 2.5: Average NDSI (snow cover) "],["simple-web-scraping-snow-studies.html", "Chapter 3 Simple web scraping Snow Studies 3.1 Scraping data 3.2 Data read-in 3.3 Plot snow data 3.4 Extract the meteorological data URLs. 3.5 Download the meteorological data. 3.6 Read data 3.7 Use the map function 3.8 Mean Air Temperture by Year 3.9 Air Temperture Error Codes 3.10 Mean Air Temperture Multiple Years 3.11 Average Daily Percipitation 3.12 Yearly Plots of Percepitation", " Chapter 3 Simple web scraping Snow Studies R can read html using either rvest, xml, or xml2 packages. Here we are going to navigate to the Center for Snow and Avalanche Studies Website and read a table in. This table contains links to data we want to programmatically download for three sites. We dont know much about these sites, but they contain incredibly rich snow, temperature, and precipitation data. 3.1 Scraping data Read the snow studies archive page to identify data for download. site_url &lt;- &#39;https://snowstudies.org/archived-data/&#39; #Read the web url webpage &lt;- read_html(site_url) #Extract only weblinks and then the URLs! links &lt;- webpage %&gt;% html_nodes(&#39;a&#39;) %&gt;% .[grepl(&#39;24hr&#39;,.)] %&gt;% html_attr(&#39;href&#39;) 3.1.1 Download the data. #Grab only the name of the file by splitting out on forward slashes splits &lt;- str_split_fixed(links,&#39;/&#39;,8) #Keep only the 8th column dataset &lt;- splits[,8] #generate a file list for where the data goes datapath = &#39;data/snow/&#39; dir.create(datapath) ## Warning in dir.create(datapath): &#39;data\\snow&#39; already exists file_names &lt;- paste0(datapath,dataset) for(i in 1:3){ download.file(links[i],destfile=file_names[i]) } downloaded &lt;- file.exists(file_names) evaluate &lt;- !all(downloaded) 3.1.2 Download data in a map #Map version of the same for loop (downloading 3 files) if(evaluate == T){ map2(links[1:3],file_names[1:3],download.file) }else{print(&#39;data already downloaded&#39;)} 3.2 Data read-in #Pattern matching to only keep certain files snow_files &lt;- file_names %&gt;% .[!grepl(&#39;SG_24&#39;,.)] %&gt;% .[!grepl(&#39;PTSP&#39;,.)] our_snow_reader &lt;- function(file){ name = str_split_fixed(file,&#39;/&#39;,2)[,2] %&gt;% gsub(&#39;_24hr.csv&#39;,&#39;&#39;,.) df &lt;- read_csv(file) %&gt;% select(Year,DOY,Sno_Height_M) %&gt;% mutate(site = name) } snow_data_full &lt;- map_dfr(snow_files,our_snow_reader) ## Rows: 6211 Columns: 52 ## -- Column specification -------------------------------------------------------- ## Delimiter: &quot;,&quot; ## dbl (52): ArrayID, Year, DOY, Hour, LoAir_Min_C, LoAir_Min_Time, LoAir_Max_C... ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. ## Rows: 6575 Columns: 48 ## -- Column specification -------------------------------------------------------- ## Delimiter: &quot;,&quot; ## dbl (48): ArrayID, Year, DOY, Hour, LoAir_Min_C, LoAir_Min_Time, LoAir_Max_C... ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. 3.3 Plot snow data ## Year DOY Sno_Height_M site ## Min. :2003 Min. : 1.0 Min. :-3.523 Length:12786 ## 1st Qu.:2008 1st Qu.: 92.0 1st Qu.: 0.350 Class :character ## Median :2012 Median :183.0 Median : 0.978 Mode :character ## Mean :2012 Mean :183.1 Mean : 0.981 ## 3rd Qu.:2016 3rd Qu.:274.0 3rd Qu.: 1.520 ## Max. :2021 Max. :366.0 Max. : 2.905 ## NA&#39;s :4554 3.4 Extract the meteorological data URLs. Here we want you to use the rvest package to get the URLs for the SASP forcing and SBSP_forcing meteorological data sets. q1_links &lt;- webpage %&gt;% html_nodes(&#39;a&#39;) %&gt;% .[grepl(&#39;forcing&#39;,.)] %&gt;% html_attr(&#39;href&#39;) 3.5 Download the meteorological data. Use the download_file and str_split_fixed commands to download the data and save it in your data folder. You can use a for loop or a map function. q2_splits &lt;- str_split_fixed(q1_links,&#39;/&#39;,8) #Keep only the 8th column q2_dataset &lt;- q2_splits[,8] q2_file_names &lt;- paste0(datapath,q2_dataset) for(i in 1:2){ download.file(q1_links[i],destfile=q2_file_names[i]) } q2_downloaded &lt;- file.exists(file_names) evaluate &lt;- !all(q2_downloaded) 3.6 Read data Write a custom function to read in the data and append a site column to the data. # this code grabs the variable names from the metadata pdf file q3_headers &lt;- pdf_text(&#39;https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf&#39;) %&gt;% readr::read_lines(.) %&gt;% trimws(.) %&gt;% str_split_fixed(.,&#39;\\\\.&#39;,2) %&gt;% .[,2] %&gt;% .[1:26] %&gt;% str_trim(side = &quot;left&quot;) q3_reader &lt;- function(file){ fileName = str_split_fixed(file,&#39;/&#39;,2)[,2] nameRight = str_split_fixed(fileName,&#39;_&#39;,2)[,2] nameLeft = str_split_fixed(nameRight,&#39;_&#39;,2)[,1] df &lt;- read.delim(file, header = FALSE, sep =&quot;&quot;,col.names = q3_headers,skip = 4) %&gt;% mutate(site = nameLeft) %&gt;% mutate(date = as.Date(paste(year, month, day, sep = &quot;-&quot;))) %&gt;% mutate(air_temp_k = air.temp..K.) %&gt;% mutate(air_temp_c = kelvin.to.celsius(air.temp..K.)) } 3.7 Use the map function Read in both meteorological files. Display a summary of your tibble. q4_full &lt;- map_dfr(q2_file_names,q3_reader) summary(q4_full[&#39;air_temp_k&#39;]) ## air_temp_k ## Min. :242.1 ## 1st Qu.:265.8 ## Median :272.6 ## Mean :272.6 ## 3rd Qu.:279.7 ## Max. :295.8 summary(q4_full[&#39;precip..kg.m.2.s.1.&#39;]) ## precip..kg.m.2.s.1. ## Min. :0.000e+00 ## 1st Qu.:0.000e+00 ## Median :0.000e+00 ## Mean :3.838e-05 ## 3rd Qu.:0.000e+00 ## Max. :6.111e-03 3.8 Mean Air Temperture by Year Make a line plot of mean temp by year by site (using the air temp [K] variable). Is there anything suspicious in the plot? Adjust your filtering if needed. Figure 3.1: Mean Air Temperture by Year Figure 3.1 shows the annual mean air temperature for both sites in a given year. 2003 &amp; 2004 have unusually low air temperatures. Figure 3.2: Boxplot Air Temperture by Year In figure 3.2 we see the air temperature in 2004 was only slightly lower, with the interquartile range being roughly the same. On the other hand 2003 had a significantly narrower interquartile range. At the scale of 1 year it is difficult to tell how much the 2003 data is skewed by collecting part of the year, if it was unusually cold that year, or if there was an issue with the instrumentation. Figure 3.3: Mean air temperture by month In 3.3 we see that it was unusually cold at both sites for the 2003 &amp; 2004 data. Much more for the SBSP. Due to only collecting data for the end of the year, 2003 data has a lower mean temperature as it does not include the summer months. Looking at the header file Serially-Complete-Metadata-text08.pdf we can see that they do include QC Code columns, but those values do not appear in the data set itself. The table of code values indicate some of the data has the followings errors, but the dates are not specified. 3.9 Air Temperture Error Codes 5001: missing data: use data from upper measurement location at same site (regression fill) 5003: missing data: use data from paired site (regression fill) 6000: before desired time period 6001: missing data: use data from upper measurement location at same site (regression fill) 6002: missing data: use data from paired site (regression fill) 6009: missing data: assume RH is 50%. 3.10 Mean Air Temperture Multiple Years Write a function that makes line plots of monthly average temperature at each site for a given year. Use a for loop to make these plots for 2005 to 2010. Are monthly average temperatures at the Senator Beck Study Plot ever warmer than the Snow Angel Study Plot? Hint: https://ggplot2.tidyverse.org/reference/print.ggplot.html Figure 3.4: Line Chart Air Temperture by Month 2005-2010 Figure 3.5: Line Chart Air Temperture by Month 2005-2010 Figure 3.6: Line Chart Air Temperture by Month 2005-2010 Figure 3.7: Line Chart Air Temperture by Month 2005-2010 Figure 3.8: Line Chart Air Temperture by Month 2005-2010 Figure 3.9: Line Chart Air Temperture by Month 2005-2010 Monthly average temperatures at the Snow Angel Study Plot are consistently warmer than the Senator Beck Study Plot. At no point from 2005 to 2010 was the Snow Angel Study Plot mean monthly temperature lower than the Senator Beck Study Plot. Figure 3.10: Line Chart Air Temperture by Month Figure 3.11: Line Chart Air Temperture by Month 3.11 Average Daily Percipitation Make a plot of average daily precipitation by day of year (averaged across all available years). Color each site. Figure 3.12: Average daily percipitation The number of years is not great enough to handle daily precipitation well. Trying monthly. Figure 3.13: Average daily percipitation in a given month That was not helpful for finding a pattern. Also note: the daily precipitation is identical at both sites. 3.12 Yearly Plots of Percepitation Use a function and for loop to create yearly plots of precipitation by day of year. Color each site. Figure 3.14: Percipitation By Month "],["lagos-spatial-analysis.html", "Chapter 4 LAGOS Spatial Analysis 4.1 Loading in data 4.2 Map of Iowa &amp; Illinois 4.3 Subset LAGOS data 4.4 Distribution of lake size in Iowa vs. Minnesota 4.5 Lakes in Iowa &amp; Illinois by lake area 4.6 Future investigation", " Chapter 4 LAGOS Spatial Analysis 4.1 Loading in data 4.1.1 First download and then specifically grab the locus (or site lat longs) #Lagos download script #LAGOSNE::lagosne_get(dest_folder = LAGOSNE:::lagos_path()) #Load in lagos lagos &lt;- lagosne_load() ## Warning in (function (version = NULL, fpath = NA) : LAGOSNE version unspecified, ## loading version: 1.087.3 #Grab the lake centroid info lake_centers &lt;- lagos$locus 4.1.2 Convert to spatial data #Look at the column names #names(lake_centers) #Look at the structure #str(lake_centers) #View the full dataset #View(lake_centers %&gt;% slice(1:100)) spatial_lakes &lt;- st_as_sf(lake_centers,coords=c(&#39;nhd_long&#39;,&#39;nhd_lat&#39;), crs=4326) %&gt;% st_transform(2163) #Subset for plotting subset_spatial &lt;- spatial_lakes %&gt;% slice(1:100) subset_baser &lt;- spatial_lakes[1:100,] #Dynamic mapviewer mapview(subset_spatial) 4.1.3 Subset to only Minnesota states &lt;- us_states() #Plot all the states to check if they loaded #mapview(states) minnesota &lt;- states %&gt;% filter(name == &#39;Minnesota&#39;) %&gt;% st_transform(2163) #Subset lakes based on spatial position minnesota_lakes &lt;- spatial_lakes[minnesota,] #Plotting the first 1000 lakes minnesota_lakes %&gt;% arrange(-lake_area_ha) %&gt;% slice(1:1000) %&gt;% mapview(.,zcol = &#39;lake_area_ha&#39;) + mapview(minnesota) 4.2 Map of Iowa &amp; Illinois #Plot all the states to check if they loaded #mapview(states) iowa &lt;- states %&gt;% filter(name == &#39;Iowa&#39;) %&gt;% st_transform(2163) illinois &lt;- states %&gt;% filter(name == &#39;Illinois&#39;) %&gt;% st_transform(2163) mapview(illinois, alpha.regions = 0.4, aplha = 1, col.regions = &quot;yellow&quot;) + mapview(iowa, alpha.regions = 0.4, aplha = 1, col.regions = &quot;red&quot;) iowa_lakes &lt;- spatial_lakes[iowa,] illinois_lakes &lt;- spatial_lakes[illinois,] 4.3 Subset LAGOS data Subset LAGOS data to these sites, how many sites are in Illinois and Iowa combined? How does this compare to Minnesota? minnesota_length = length(minnesota_lakes$lagoslakeid) iowa_illinois_lakes = rbind(illinois_lakes, iowa_lakes) iowa_illinois_length = length(iowa_illinois_lakes$lagoslakeid) Minnesota has 29038 lakes while Iowa &amp; Illinois combined have 16466 lakes 4.4 Distribution of lake size in Iowa vs. Minnesota Minnesota has bigger lakes than Iowa. Both are skewed to the right. Figure 4.1: Distribution of lake size in Iowa vs. Minnesota 4.5 Lakes in Iowa &amp; Illinois by lake area iowa_illinois_map = iowa_illinois_lakes %&gt;% arrange(-lake_area_ha) %&gt;% slice(1:1000) %&gt;% mapview(.,zcol = &#39;lake_area_ha&#39;, canvas = TRUE, at=c(0,10,100,1000,10000)) mapview(illinois, canvas = TRUE , alpha.regions = 0.4, aplha = 1, col.regions = &quot;yellow&quot;) + mapview(iowa, canvas = TRUE , alpha.regions = 0.4, aplha = 1, col.regions = &quot;red&quot;) + iowa_illinois_map 4.6 Future investigation What other data sources might we use to understand how reservoirs and natural lakes vary in size in these three states? Ground water &amp; especially water table depth data would be helpful for looking at how the lakes interact with one another. Long term weather &amp; climate (rainfall, snowfall, and Total Solar Radiance) would be helpful in to for understanding water origin &amp; evaporation. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
