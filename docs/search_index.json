[["index.html", "Data Science Demo Introduction View GitHub Code", " Data Science Demo Brandon Budnicki 2022-03-23 Introduction This R Bookdown website is my final project for the Introduction to Data Science Course ESS 580A7. I took this class in the Spring semester of 2022 as part of my candidacy in the Ecosystem Science &amp; Sustainability (ESS) PHD program at Colorado State University. Later chapters demonstrate a progression in anlaytical complexity. View GitHub Code The code used to build this R Bookdown is hosted on GitHub. Data Science Demo GitHub "],["poudre-river-interactive-graph.html", "Chapter 1 Poudre River Interactive Graph 1.1 Methods 1.2 SiteDescription 1.3 Data Acquisition 1.4 Interactive Plot 1.5 Cameron Peak Fire", " Chapter 1 Poudre River Interactive Graph The Poudre river goes through northern Colorado through Fort Collins. By graphing the flow rate over time we can spot annual patterns &amp; sever weather events. Discharge data is downloaded by the dataRetrieval R package from the NWIS web service waterservices.usgs.gov 1.1 Methods The Poudre River at Lincoln Bridge is: Downstream of only a little bit of urban stormwater Near Odell Brewing CO Near an open space area and the Poudre River Trail Downstream of many agricultral diversions 1.2 SiteDescription 1.3 Data Acquisition q &lt;- readNWISdv( siteNumbers = &#39;06752260&#39;, parameterCd = &#39;00060&#39;, startDate = &#39;2017-01-01&#39;, endDate = &#39;2022-01-01&#39; ) %&gt;% rename(q = &#39;X_00060_00003&#39;) q_xts &lt;- xts(q$q, order.by = q$Date) 1.4 Interactive Plot series &lt;- cbind(points = q_xts) dygraph(series, main = &quot;Discharge in the Poudre River&quot;) %&gt;% dySeries(&quot;points&quot;, label = &quot;7 Day Averae&quot;, drawPoints = TRUE, pointSize = 3) %&gt;% dyAnnotation(&quot;2018-7-24&quot;, text = &quot;C&quot;, tooltip = &quot;Peak discharge&quot;) %&gt;% dyAnnotation(&quot;2018-7-22&quot;, text = &quot;B&quot;, tooltip = &quot;Larimer County lifts evacuation orders&quot;) %&gt;% dyAnnotation(&quot;2018-7-21&quot;, text = &quot;A&quot;, tooltip = &quot;Larimer County officials closed the Poudre River for all uses&quot;) %&gt;% dyRoller(rollPeriod = 1) %&gt;% dyRangeSelector(dateWindow = c(&quot;2018-07-01&quot;, &quot;2018-8-01&quot;)) %&gt;% dyAxis(&quot;y&quot;, label = &quot;Discharge (cfs)&quot;) Figure 1.1: Discharge in the Poudre River at the Lincoln Bride in Fort Collins, CO 1.5 Cameron Peak Fire Burn scars caused by the Cameron peak fire lead to dangerous discharge within the Poudre River on July 21st 2018 (Label A 1.1). Larimer County officials closed the Poudre River for all use and issued evacuation orders, finally reopening on July 22nd (Label B 1.1). These flood warnings were issued and then lifted before the peak discharge from this rainfall event on July 24th (Label C 1.1). "],["hayman-fire-google-earth-engine.html", "Chapter 2 Hayman Fire Google Earth Engine 2.1 NDVI over time 2.2 Correlation between NDVI &amp; NDMI 2.3 Snow and Vegitation 2.4 Greenest Month 2.5 Snowiest Month", " Chapter 2 Hayman Fire Google Earth Engine The Hayman Fire occurred June 8,2002 and was at the time the largest recorded wildfire in Colorado. By using Google Earth Engine to download remote sensing data, we can look at the impact the wildfire had on vegetation. Normalized Difference Vegetation Index (NDVI) Normalized Difference Snow Index (NDSI) Normalized Difference Moisture Index (NDMI) 2.1 NDVI over time There was a clear decrease in NDVI from pre to post burn at Site 2. Site 1 also saw a decrease, albeit quite a bit smaller. Figure 2.1: NDVI over time 2.2 Correlation between NDVI &amp; NDMI Exploring the correlation between NDVI &amp; NDMI looking at the summer months we can see that as surface moisture increases, vegetation increases. Site 2 saw a decrease in surface moisture and vegetation following the same ratio between NDVI and NDMI. Figure 2.2: Impact of surface moisture on vegatitation 2.3 Snow and Vegitation Looking at the previous years snow cover, we show little if any influence on vegetation growth the following summer. Both for the Site 1 &amp; Site 2 pre burn. There is a clear shift in vegetation due to the impacts of burned areas 2.3 from site 2 pre burn to site 2 post burn. The snow cover had lower maximums during this time. This could be due to darker surfaces but also could be due to outside factors such as warmer winters. Based on the sample size it is difficult to tell from this data. Figure 2.3: Impact of snow cover on vegatative growth 2.4 Greenest Month August is the greenest month based on the Normalized Difference Vegetation Index. This holds true for both unburned &amp; burned sites. Figure 2.4: Vegitation (NDVI) by Month 2.5 Snowiest Month Snow cover was greatest in January &amp; February. Site 1 had greater cover than site 2. This can be used as a proxy for snow fall, but is not a direct measurement as the freeze thaw cycle impacts the cover. Interestingly the snow cover post burn at site 2 was less than pre burn. This might be caused by a number of factors related or not related to the burn as theorized in 2.3. Figure 2.5: Average NDSI (snow cover) "],["simple-web-scraping-snow-studies.html", "Chapter 3 Simple web scraping Snow Studies 3.1 Scraping data 3.2 Data read-in 3.3 Plot snow data 3.4 Extract the meteorological data URLs. 3.5 Download the meteorological data. 3.6 Read data 3.7 Use the map function 3.8 Mean Air Temperture by Year 3.9 Air Temperture Error Codes 3.10 Mean Air Temperture Multiple Years 3.11 Average Daily Percipitation 3.12 Yearly Plots of Percepitation", " Chapter 3 Simple web scraping Snow Studies R can read html using either rvest, xml, or xml2 packages. Here we are going to navigate to the Center for Snow and Avalanche Studies Website and read a table in. This table contains links to data we want to programmatically download for three sites. We dont know much about these sites, but they contain incredibly rich snow, temperature, and precipitation data. 3.1 Scraping data Read the snow studies archive page to identify data for download. site_url &lt;- &#39;https://snowstudies.org/archived-data/&#39; #Read the web url webpage &lt;- read_html(site_url) #Extract only weblinks and then the URLs! links &lt;- webpage %&gt;% html_nodes(&#39;a&#39;) %&gt;% .[grepl(&#39;24hr&#39;,.)] %&gt;% html_attr(&#39;href&#39;) 3.1.1 Download the data. #Grab only the name of the file by splitting out on forward slashes splits &lt;- str_split_fixed(links,&#39;/&#39;,8) #Keep only the 8th column dataset &lt;- splits[,8] #generate a file list for where the data goes datapath = &#39;data/snow/&#39; dir.create(datapath) file_names &lt;- paste0(datapath,dataset) for(i in 1:3){ download.file(links[i],destfile=file_names[i]) } downloaded &lt;- file.exists(file_names) evaluate &lt;- !all(downloaded) 3.1.2 Download data in a map #Map version of the same for loop (downloading 3 files) if(evaluate == T){ map2(links[1:3],file_names[1:3],download.file) }else{print(&#39;data already downloaded&#39;)} 3.2 Data read-in #Pattern matching to only keep certain files snow_files &lt;- file_names %&gt;% .[!grepl(&#39;SG_24&#39;,.)] %&gt;% .[!grepl(&#39;PTSP&#39;,.)] our_snow_reader &lt;- function(file){ name = str_split_fixed(file,&#39;/&#39;,2)[,2] %&gt;% gsub(&#39;_24hr.csv&#39;,&#39;&#39;,.) df &lt;- read_csv(file) %&gt;% select(Year,DOY,Sno_Height_M) %&gt;% mutate(site = name) } snow_data_full &lt;- map_dfr(snow_files,our_snow_reader) ## Rows: 6211 Columns: 52 ## -- Column specification -------------------------------------------------------- ## Delimiter: &quot;,&quot; ## dbl (52): ArrayID, Year, DOY, Hour, LoAir_Min_C, LoAir_Min_Time, LoAir_Max_C... ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. ## Rows: 6575 Columns: 48 ## -- Column specification -------------------------------------------------------- ## Delimiter: &quot;,&quot; ## dbl (48): ArrayID, Year, DOY, Hour, LoAir_Min_C, LoAir_Min_Time, LoAir_Max_C... ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. 3.3 Plot snow data ## Year DOY Sno_Height_M site ## Min. :2003 Min. : 1.0 Min. :-3.523 Length:12786 ## 1st Qu.:2008 1st Qu.: 92.0 1st Qu.: 0.350 Class :character ## Median :2012 Median :183.0 Median : 0.978 Mode :character ## Mean :2012 Mean :183.1 Mean : 0.981 ## 3rd Qu.:2016 3rd Qu.:274.0 3rd Qu.: 1.520 ## Max. :2021 Max. :366.0 Max. : 2.905 ## NA&#39;s :4554 3.4 Extract the meteorological data URLs. Here we want you to use the rvest package to get the URLs for the SASP forcing and SBSP_forcing meteorological data sets. q1_links &lt;- webpage %&gt;% html_nodes(&#39;a&#39;) %&gt;% .[grepl(&#39;forcing&#39;,.)] %&gt;% html_attr(&#39;href&#39;) 3.5 Download the meteorological data. Use the download_file and str_split_fixed commands to download the data and save it in your data folder. You can use a for loop or a map function. q2_splits &lt;- str_split_fixed(q1_links,&#39;/&#39;,8) #Keep only the 8th column q2_dataset &lt;- q2_splits[,8] q2_file_names &lt;- paste0(datapath,q2_dataset) for(i in 1:2){ download.file(q1_links[i],destfile=q2_file_names[i]) } q2_downloaded &lt;- file.exists(file_names) evaluate &lt;- !all(q2_downloaded) 3.6 Read data Write a custom function to read in the data and append a site column to the data. # this code grabs the variable names from the metadata pdf file q3_headers &lt;- pdf_text(&#39;https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf&#39;) %&gt;% readr::read_lines(.) %&gt;% trimws(.) %&gt;% str_split_fixed(.,&#39;\\\\.&#39;,2) %&gt;% .[,2] %&gt;% .[1:26] %&gt;% str_trim(side = &quot;left&quot;) q3_reader &lt;- function(file){ fileName = str_split_fixed(file,&#39;/&#39;,2)[,2] nameRight = str_split_fixed(fileName,&#39;_&#39;,2)[,2] nameLeft = str_split_fixed(nameRight,&#39;_&#39;,2)[,1] df &lt;- read.delim(file, header = FALSE, sep =&quot;&quot;,col.names = q3_headers,skip = 4) %&gt;% mutate(site = nameLeft) %&gt;% mutate(date = as.Date(paste(year, month, day, sep = &quot;-&quot;))) %&gt;% mutate(air_temp_k = air.temp..K.) %&gt;% mutate(air_temp_c = kelvin.to.celsius(air.temp..K.)) } 3.7 Use the map function Read in both meteorological files. Display a summary of your tibble. q4_full &lt;- map_dfr(q2_file_names,q3_reader) summary(q4_full[&#39;air_temp_k&#39;]) ## air_temp_k ## Min. :242.1 ## 1st Qu.:265.8 ## Median :272.6 ## Mean :272.6 ## 3rd Qu.:279.7 ## Max. :295.8 summary(q4_full[&#39;precip..kg.m.2.s.1.&#39;]) ## precip..kg.m.2.s.1. ## Min. :0.000e+00 ## 1st Qu.:0.000e+00 ## Median :0.000e+00 ## Mean :3.838e-05 ## 3rd Qu.:0.000e+00 ## Max. :6.111e-03 3.8 Mean Air Temperture by Year Make a line plot of mean temp by year by site (using the air temp [K] variable). Is there anything suspicious in the plot? Adjust your filtering if needed. Figure 3.1: Mean Air Temperture by Year Figure 3.1 shows the annual mean air temperature for both sites in a given year. 2003 &amp; 2004 have unusually low air temperatures. Figure 3.2: Boxplot Air Temperture by Year In figure 3.2 we see the air temperature in 2004 was only slightly lower, with the interquartile range being roughly the same. On the other hand 2003 had a significantly narrower interquartile range. At the scale of 1 year it is difficult to tell how much the 2003 data is skewed by collecting part of the year, if it was unusually cold that year, or if there was an issue with the instrumentation. Figure 3.3: Mean air temperture by month In 3.3 we see that it was unusually cold at both sites for the 2003 &amp; 2004 data. Much more for the SBSP. Due to only collecting data for the end of the year, 2003 data has a lower mean temperature as it does not include the summer months. Looking at the header file Serially-Complete-Metadata-text08.pdf we can see that they do include QC Code columns, but those values do not appear in the data set itself. The table of code values indicate some of the data has the followings errors, but the dates are not specified. 3.9 Air Temperture Error Codes 5001: missing data: use data from upper measurement location at same site (regression fill) 5003: missing data: use data from paired site (regression fill) 6000: before desired time period 6001: missing data: use data from upper measurement location at same site (regression fill) 6002: missing data: use data from paired site (regression fill) 6009: missing data: assume RH is 50%. 3.10 Mean Air Temperture Multiple Years Write a function that makes line plots of monthly average temperature at each site for a given year. Use a for loop to make these plots for 2005 to 2010. Are monthly average temperatures at the Senator Beck Study Plot ever warmer than the Snow Angel Study Plot? Hint: https://ggplot2.tidyverse.org/reference/print.ggplot.html Figure 3.4: Line Chart Air Temperture by Month 2005-2010 Figure 3.5: Line Chart Air Temperture by Month 2005-2010 Figure 3.6: Line Chart Air Temperture by Month 2005-2010 Figure 3.7: Line Chart Air Temperture by Month 2005-2010 Figure 3.8: Line Chart Air Temperture by Month 2005-2010 Figure 3.9: Line Chart Air Temperture by Month 2005-2010 Monthly average temperatures at the Snow Angel Study Plot are consistently warmer than the Senator Beck Study Plot. At no point from 2005 to 2010 was the Snow Angel Study Plot mean monthly temperature lower than the Senator Beck Study Plot. Figure 3.10: Line Chart Air Temperture by Month Figure 3.11: Line Chart Air Temperture by Month 3.11 Average Daily Percipitation Make a plot of average daily precipitation by day of year (averaged across all available years). Color each site. Figure 3.12: Average daily percipitation The number of years is not great enough to handle daily precipitation well. Trying monthly. Figure 3.13: Average daily percipitation in a given month That was not helpful for finding a pattern. Also note: the daily precipitation is identical at both sites. 3.12 Yearly Plots of Percepitation Use a function and for loop to create yearly plots of precipitation by day of year. Color each site. Figure 3.14: Percipitation By Month "],["lagos-spatial-analysis.html", "Chapter 4 LAGOS Spatial Analysis 4.1 Loading in data 4.2 Map of Iowa &amp; Illinois 4.3 Subset LAGOS data 4.4 Distribution of lake size in Iowa vs. Minnesota 4.5 Lakes in Iowa &amp; Illinois by lake area 4.6 Future investigation", " Chapter 4 LAGOS Spatial Analysis lagoslakes.org collects data for studying lakes through time. Here we visualize lakes in Minnesota, Iowa, &amp; Illinois geospatially using Leaflet. 4.1 Loading in data 4.1.1 First download and then specifically grab the locus (or site lat longs) #Lagos download script #LAGOSNE::lagosne_get(dest_folder = LAGOSNE:::lagos_path()) #Load in lagos lagos &lt;- lagosne_load() ## Warning in (function (version = NULL, fpath = NA) : LAGOSNE version unspecified, ## loading version: 1.087.3 #Grab the lake centroid info lake_centers &lt;- lagos$locus 4.1.2 Convert to spatial data #Look at the column names #names(lake_centers) #Look at the structure #str(lake_centers) #View the full dataset #View(lake_centers %&gt;% slice(1:100)) spatial_lakes &lt;- st_as_sf(lake_centers,coords=c(&#39;nhd_long&#39;,&#39;nhd_lat&#39;), crs=4326) %&gt;% st_transform(2163) #Subset for plotting subset_spatial &lt;- spatial_lakes %&gt;% slice(1:100) subset_baser &lt;- spatial_lakes[1:100,] #Dynamic mapviewer #mapview(subset_spatial, layer.name=&quot;Lakes&quot;) 4.1.3 Subset to only Minnesota states &lt;- us_states() #Plot all the states to check if they loaded #mapview(states) minnesota &lt;- states %&gt;% filter(name == &#39;Minnesota&#39;) %&gt;% st_transform(2163) #Subset lakes based on spatial position minnesota_lakes &lt;- spatial_lakes[minnesota,] #Plotting the first 1000 lakes minnesota_lakes %&gt;% arrange(-lake_area_ha) %&gt;% slice(1:1000) %&gt;% mapview(.,zcol = &#39;lake_area_ha&#39;, layer.name=&quot;Lake Area (HA)&quot;) + mapview(minnesota) 4.2 Map of Iowa &amp; Illinois #Plot all the states to check if they loaded #mapview(states) #polygon for Iowa iowa &lt;- states %&gt;% filter(name == &#39;Iowa&#39;) %&gt;% st_transform(2163) #Ploygon for Illionois illinois &lt;- states %&gt;% filter(name == &#39;Illinois&#39;) %&gt;% st_transform(2163) #Digplay combined map mapview(illinois, alpha.regions = 0.4, aplha = 1, col.regions = &quot;yellow&quot;) + mapview(iowa, alpha.regions = 0.4, aplha = 1, col.regions = &quot;red&quot;) #Filter lakes based on state iowa_lakes &lt;- spatial_lakes[iowa,] illinois_lakes &lt;- spatial_lakes[illinois,] 4.3 Subset LAGOS data Subset LAGOS data to these sites, how many sites are in Illinois and Iowa combined? How does this compare to Minnesota? # Create bar chart of lakes size distribution minnesota_length = length(minnesota_lakes$lagoslakeid) iowa_illinois_lakes = rbind(illinois_lakes, iowa_lakes) iowa_illinois_length = length(iowa_illinois_lakes$lagoslakeid) Minnesota has 29038 lakes while Iowa &amp; Illinois combined have 16466 lakes 4.4 Distribution of lake size in Iowa vs. Minnesota Minnesota has bigger lakes than Iowa. Both are skewed to the right. Figure 4.1: Distribution of lake size in Iowa vs. Minnesota 4.5 Lakes in Iowa &amp; Illinois by lake area # Arrange lakes so larger ones are on top iowa_illinois_map = iowa_illinois_lakes %&gt;% arrange(-lake_area_ha) %&gt;% slice(1:1000) %&gt;% mapview(.,zcol = &#39;lake_area_ha&#39;, layer.name=&quot;Lake Area (HA)&quot;, canvas = TRUE, at=c(0,10,100,1000,10000)) # Combine map layersfor display mapview(illinois, canvas = TRUE , alpha.regions = 0.4, aplha = 1, col.regions = &quot;yellow&quot;) + mapview(iowa, canvas = TRUE , alpha.regions = 0.4, aplha = 1, col.regions = &quot;red&quot;) + iowa_illinois_map 4.6 Future investigation What other data sources might we use to understand how reservoirs and natural lakes vary in size in these three states? Ground water &amp; especially water table depth data would be helpful for looking at how the lakes interact with one another. Long term weather &amp; climate (rainfall, snowfall, and Total Solar Radiance) would be helpful in to for understanding water origin &amp; evaporation. "],["lagosne-water-quality-analysis.html", "Chapter 5 LAGOSNE Water Quality Analysis 5.1 Loading in data 5.2 Mean Chlorophyll A map 5.3 Correlation between Secchi Disk Depth and Chlorophyll A 5.4 Which states have the most data? 5.5 Why 200 observations 5.6 25 observations per lake", " Chapter 5 LAGOSNE Water Quality Analysis lagoslakes.org archives observations of lakes over time. Here we visualize lakes in Minnesota, Iowa, &amp; Illinois geospatially using Leaflet. In this analysis we will look at Chlorophyll A &amp; Secchi depth (meters). Chlorophyll A (micro grams / liter) is a proxy measure for the amount of algae in a water body. Secchi depth is a measure of water clarity. 5.1 Loading in data 5.1.1 Download and identify the site locus(latiutde longitude) #Lagos download script #lagosne_get(dest_folder = LAGOSNE:::lagos_path(),overwrite=T) #Load in lagos lagos &lt;- lagosne_load() #Grab the lake centroid info lake_centers &lt;- lagos$locus # Make an sf object spatial_lakes &lt;- st_as_sf(lake_centers,coords=c(&#39;nhd_long&#39;,&#39;nhd_lat&#39;), crs=4326) #Grab the water quality data nutr &lt;- lagos$epi_nutr #Look at column names #names(nutr) # subset columns nutr to only keep key info that we want clarity_only &lt;- nutr %&gt;% dplyr::select(lagoslakeid,sampledate,chla,doc,secchi) %&gt;% mutate(sampledate = as.character(sampledate) %&gt;% ymd(.)) 5.1.2 Filter sites with at least 200 observations This is done to ensure we have enough data for a given lake to conduct analysis. This was arbitrarily chosen. See Why 200 observations for an analysis of the distribution of observations per lake. #Look at the number of rows of data #nrow(clarity_only) chla_secchi &lt;- clarity_only %&gt;% filter(!is.na(chla), !is.na(secchi)) # How many observatiosn did we lose? filteredObservations = nrow(clarity_only) - nrow(chla_secchi) # Keep only the lakes with at least 200 observations of secchi and chla chla_secchi_200 &lt;- chla_secchi %&gt;% group_by(lagoslakeid) %&gt;% mutate(count = n()) %&gt;% filter(count &gt; 200) # Join water quality data to spatial data spatial_200 &lt;- inner_join( spatial_lakes,chla_secchi_200 %&gt;% distinct(lagoslakeid,.keep_all=T), by=&#39;lagoslakeid&#39; ) We lost 651095 observations because they were missing Secchi or Chlorophyll data. 5.2 Mean Chlorophyll A map ### Take the mean Chlorophyll A and Secchi by lake mean_values_200 &lt;- chla_secchi_200 %&gt;% # Take summary by lake id group_by(lagoslakeid) %&gt;% # take mean chl_a per lake id summarize( mean_chla = mean(chla,na.rm=T), mean_secchi=mean(secchi,na.rm=T) ) %&gt;% #Get rid of NAs filter( !is.na(mean_chla), !is.na(mean_secchi) ) %&gt;% # Take the log base 10 of the mean_chl mutate(log10_mean_chla = log10(mean_chla)) #Join datasets mean_spatial &lt;- inner_join( spatial_lakes, mean_values_200, by=&#39;lagoslakeid&#39; ) #Make a map mapview(mean_spatial,zcol=&#39;log10_mean_chla&#39;, layer.name = &#39;Mean Chlorophyll A Log 10&#39;) 5.3 Correlation between Secchi Disk Depth and Chlorophyll A Chlorophyll blocks light and obscures the secchi disk. As chlorophyll increases, Secchi depth decreases. Additionally algae are the primary producers of chlorophyll along with weeds. Lakes that have a higher nutrient load leads to more chlorophyll, these dissolved nutrients also tend to cloud waters and obscure secchi disks. Finally, deeper lakes tend to produce less photosynthetic algae due to increased mechanical mixing of different water layers. Figure 5.1: Secchi depth vs Chlorophyll 5.4 Which states have the most data? # Make a lagos spatial dataset that has the total number of counts per site. # Get count for each lake lago_summary = chla_secchi %&gt;% #slice(1:10000) %&gt;% group_by(lagoslakeid) %&gt;% summarize( mean_chla = mean(chla,na.rm=T), mean_secchi=mean(secchi,na.rm=T), count=n() ) ## Join to lake location lago_location_summary = merge( x = lago_summary, y = lake_centers, by = &quot;lagoslakeid&quot;, all.x = TRUE ) %&gt;% st_as_sf(coords=c(&#39;nhd_long&#39;,&#39;nhd_lat&#39;),crs=4326) # Show all points on the map #mapview(lago_location_summary) # join this point dataset to the us_boundaries data. state_bounds = us_states() %&gt;% dplyr::select(state_name,state_abbr) lago_location_summary_join_state = st_join( x = lago_location_summary, y = state_bounds, left = TRUE ) lago_location_summary_join_state_200 = lago_location_summary_join_state %&gt;% filter(count &gt; 200) # Group by state and sum all the observations in that state and arrange that data from most to least total observations per state. state_data = lago_location_summary_join_state %&gt;% group_by(state_name) %&gt;% summarize( mean_chla = mean(mean_chla,na.rm=T), mean_secchi=mean(mean_secchi,na.rm=T), count=sum(count) ) %&gt;% arrange(desc(count)) # verify all observations totaled correctly **success** #sum(state_data$count) state_data_200 = lago_location_summary_join_state_200 %&gt;% group_by(state_name) %&gt;% summarize( mean_chla = mean(mean_chla,na.rm=T), mean_secchi=mean(mean_secchi,na.rm=T), count=sum(count) ) %&gt;% arrange(desc(count)) # map of where state with most values are state_obs_count = st_join( x = state_bounds, y = state_data, left = TRUE ) # map of where state with most values are state_obs_count_200 = st_join( x = state_bounds, y = state_data_200, left = TRUE ) 5.4.1 Number of observations for all lakes 5.4.2 Number of observations for lakes with more than 200 observations 5.4.3 Spatial pattern in Secchi disk depth for lakes with at least 200 observations The lakes with more than 200 observations are all centered on urban areas. This show more of a bias towards the accessibility rather than a spatial connection with secchi disk depths. 5.5 Why 200 observations Histogram 5.2 shows the distribution of observations / lake. The 200 observations per lake is somewhat arbitrary. Looking at 10 to 50 observations per lake would capture more than the outlier lakes with an extreme amount of observation activity. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 5.2: Distribution of observations / lake 5.6 25 observations per lake At 25 observations per lake this demonstrates 2 clear spatial relations for Secchi depth: Increasing latitude is positively correlated with Secchi depth. This could be to decreased agricultural activity in the north. Increased distance from population centers is positively correclated with Secchi depth. This could be to less human made pollution adding nutrient to the water. "],["weather-and-agricultural-yield-regressions.html", "Chapter 6 Weather and Agricultural Yield Regressions 6.1 Counties 6.2 Temperture 6.3 Corn 6.4 Soybeans 6.5 Corn VS Soy", " Chapter 6 Weather and Agricultural Yield Regressions By looking at weather patterns we can gleam new insight into farm yields. Here we use PRISM temperture data and NASS corn &amp; soybean yield data. 6.1 Counties Get all counties in Iowa counties = us_counties(map_date = NULL, resolution = c(&quot;low&quot;, &quot;high&quot;), states = &#39;iowa&#39;) %&gt;% dplyr::select(name, geometry) counties$name = tolower(counties$name) 6.2 Temperture Load the PRISM daily maximum temperatures for Iowa # daily max temperature # dimensions: counties x days x years prism &lt;- readMat(&quot;data/corn/prismiowa.mat&quot;) # view data for county #1 t_1981_c1 &lt;- prism$tmaxdaily.iowa[1,,1] #t_1981_c1[366] ggplot() + geom_line(mapping = aes(x=1:366, y = t_1981_c1)) + theme_bw() + xlab(&quot;Day of Year&quot;) + ylab(&quot;Daily Maximum Temperature (°C)&quot;) + ggtitle(&quot;Daily Maximum Temperature, Iowa County #1&quot;) Figure 6.1: Daily Maximum Temperature, Iowa County #1 # assign dimension names to tmax matrix dimnames(prism$tmaxdaily.iowa) &lt;- list(prism$COUNTYFP, 1:366, prism$years) # converted 3d matrix into a data frame tmaxdf &lt;- as.data.frame.table(prism$tmaxdaily.iowa) # relabel the columns colnames(tmaxdf) &lt;- c(&quot;countyfp&quot;,&quot;doy&quot;,&quot;year&quot;,&quot;tmax&quot;) tmaxdf &lt;- tibble(tmaxdf) 6.2.1 Summer temperature trends: Winneshiek County Figure 6.2: Summer temperature trends: Winneshiek County ## ## Call: ## lm(formula = meanTmax ~ year, data = winneSummer) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.5189 -0.7867 -0.0341 0.6859 3.7415 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 41.57670 36.44848 1.141 0.262 ## year -0.00747 0.01823 -0.410 0.684 ## ## Residual standard error: 1.232 on 36 degrees of freedom ## Multiple R-squared: 0.004644, Adjusted R-squared: -0.02301 ## F-statistic: 0.168 on 1 and 36 DF, p-value: 0.6844 6.2.2 Winter temperature trends: Winneshiek County Figure 6.3: Winter temperature trends: Winneshiek County ## ## Call: ## lm(formula = meanTmax ~ year, data = winneWinter) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.5978 -1.4917 -0.3053 1.3778 4.5709 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -29.87825 60.48100 -0.494 0.624 ## year 0.01368 0.03025 0.452 0.654 ## ## Residual standard error: 2.045 on 36 degrees of freedom ## Multiple R-squared: 0.005652, Adjusted R-squared: -0.02197 ## F-statistic: 0.2046 on 1 and 36 DF, p-value: 0.6537 6.2.3 Multiple Regression - Quadratic Time Trend Figure 6.4: Multiple Regression - Quadratic Time Trend ## ## Call: ## lm(formula = meanTmax ~ year + yearSq, data = winneWinter) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.3539 -1.2985 -0.2813 1.4055 4.2620 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.086e+04 1.238e+04 -0.877 0.386 ## year 1.085e+01 1.239e+01 0.876 0.387 ## yearSq -2.710e-03 3.097e-03 -0.875 0.388 ## ## Residual standard error: 2.051 on 35 degrees of freedom ## Multiple R-squared: 0.02694, Adjusted R-squared: -0.02867 ## F-statistic: 0.4845 on 2 and 35 DF, p-value: 0.6201 6.3 Corn Download NASS corn yield data # set our API key with NASS. Stored in the env to prevent publishing on GitHub # You can get your own key by visiting: # https://quickstats.nass.usda.gov/api nassqs_key &lt;- Sys.getenv(&quot;nassqs_auth&quot;) nassqs_auth(key = nassqs_key) # parameters to query on params &lt;- list(commodity_desc = &quot;CORN&quot;, util_practice_desc = &quot;GRAIN&quot;, prodn_practice_desc = &quot;ALL PRODUCTION PRACTICES&quot;, year__GE = 1981, state_alpha = &quot;IA&quot;) #cornyieldsall &lt;- nassqs_yields(params) # clean and filter this dataset cornyieldsall$county_ansi &lt;- as.numeric(cornyieldsall$county_ansi) cornyieldsall$year &lt;- as.numeric(cornyieldsall$year) cornyieldsall$yield &lt;- as.numeric(cornyieldsall$Value) cornyields &lt;- dplyr::select(cornyieldsall, county_ansi, county_name, yield, year) %&gt;% filter(!is.na(county_ansi) &amp; !is.na(yield)) cornyields$county_name = tolower(cornyields$county_name) cornyields &lt;- tibble(cornyields) 6.3.1 Yield over time Corn yield has consistently increased year over year. For the linear model, with every increasing year we would expect an increase in yield of 2.457 bushels / acre. This agrees with my prior knowledge from working at Land OLakes. Improvements in farming practices and seed genetics have been driving this trend. Although adoption of these changes varies from farm to farm, at the aggregated county level this affect can be clearly seen in the data. Figure 6.5: Yield over time 6.3.2 Quadratic time trend There is no evidence of slowing corn yield growth in Winneshiek County, IA. The slope of the quadratic time model is relatively constant over time, if anything there is slight acceleration. winneYieldLin&lt;- lm(yield ~ year, winneYield) #summary(winneYieldLin) winneYield$lin &lt;- winneYieldLin$fitted.values winneYield$yearSq &lt;- as.numeric(winneYield$year)^2 winneYieldQuad&lt;- lm(yield ~ year + yearSq, winneYield) #summary(winneYieldQuad) winneYield$quad &lt;- winneYieldQuad$fitted.values ggplot(winneYield) + geom_point(mapping = aes(x = year, y = yield), alpha = 0.4, colour = &quot;black&quot;) + geom_line(mapping = aes(x = year, y = quad, col=&#39;Quadratic Year&#39;), size=1) + geom_line(mapping = aes(x = year, y = lin, col=&#39;Linear Year&#39;), size=1) + theme_bw() + labs(x = &quot;Year&quot;, y = &quot;Yield (bsh/ac)&quot;, title= &quot;Yield over time&quot;, subtitle=&quot;Winneshiek, IA&quot;, color = &quot;Model&quot;) Figure 6.6: Corn Quadratic Time Trend 6.3.3 Time Series The yield peaks at a mean summer temperature max of 27 Celsius according to the quadratic temp model.This follows intuition that plants respond well to increasing temperature, if it was freezing they would not grow. However, increased temperature only increases yield up to 27 degrees than than gradually drops. The quadratic temperature model has significantly greater predictive performance than the linear. However with such a significant year over year affect, the Quadratic Temp Year model has the best performance. We can see that Year Squared has a significantly bigger affect on Yield than the Temperature does as shown by the p-values of the coefficients. By incorporating year quared &amp; mean temperture max squared, we account for 81% of the variation observed in yield (Adjusted R-squared). # add squares for quadratic modeling winneYieldTemp = merge(winneYield, winneSummer, by = &#39;year&#39;) %&gt;% mutate( yieldSq = yield^2, meanTmaxSq = meanTmax^2 ) # Linear model of Tmax on Yield winneYieldTempLin&lt;- lm(yield ~ meanTmax, winneYieldTemp) winneYieldTemp$tempLin &lt;- winneYieldTempLin$fitted.values # Quadratic model of year on yield winneYieldTempQuad&lt;- lm(yield ~ meanTmax + meanTmaxSq, winneYieldTemp) winneYieldTemp$tempQuad &lt;- winneYieldTempQuad$fitted.values # Linear model of year &amp; Tmax on yield winneYieldYearLinTempLin&lt;- lm(yield ~ meanTmax + year, winneYieldTemp) winneYieldTemp$yearTempLin &lt;- winneYieldYearLinTempLin$fitted.values # Quadratic model of year &amp; Tmax on yield winneYieldYearTempQuad&lt;- lm(yield ~ year + yearSq + meanTmax + meanTmaxSq, winneYieldTemp) winneYieldTemp$yearTempQuad &lt;- winneYieldYearTempQuad$fitted.values #summary(winneYieldYearTempQuad$coefficients) Figure 6.7: Yield models 6.3.4 Time Cross-Section We see the same relationship between Summer Mean T Max and Yield in 2018 for all counties in Iowa that we saw for all years in Winneshiek. The peak is at 28 degrees instead of 27 degrees. This data tells the story better, as unlike the Winneshiek analysis, this is not affected by year of year yield increases due to improved farming methods. Looking at only one year the p-value of the mean temperture mac goes from 0.0005 to 0.00239 when we only look at one year of data. tmaxAll = tmaxdf %&gt;% filter(doy &gt;= 152 &amp; doy &lt;= 243) %&gt;% group_by(year, countyfp) %&gt;% summarize(meanTmax = mean(tmax)) iowa = merge(cornyields, tmaxAll, by.x=c(&quot;year&quot;, &quot;county_ansi&quot;), by.y=c(&quot;year&quot;, &quot;countyfp&quot;)) %&gt;% mutate( yearSq = as.numeric(year)^2, yieldSq = yield^2, meanTmaxSq = meanTmax ^ 2 ) iowa2018 = iowa %&gt;% filter(year == 2018) iowa2018YieldTempLin&lt;- lm(yield ~ meanTmax, iowa2018) #summary(iowa2018YieldTempLin) iowa2018$lin &lt;- iowa2018YieldTempLin$fitted.values iowa2018YieldTempQuad&lt;- lm(yield ~ meanTmax + meanTmaxSq, iowa2018) #summary(iowa2018YieldTempQuad) iowa2018$quad &lt;- iowa2018YieldTempQuad$fitted.values Figure 6.8: Corn Yield over T Max for Iowa in 2018 6.3.5 Panel Regession One way to leverage multiple time series is to group all data into what is called a panel regression. Combined the yield models tell a more complete picture with an Adjusted R-squared of 0.7225 . On its own, the quadratic temperature model only have predictive power up to 150 bushels, after which all increases are dependent on factors outside of temperature. The year model provides the best single factor fit, following the slope most tightly. The county also plays a large factor in that a 50 bushel difference can be attributed to the location of your farm. Some counties had a greater signficance like CLARKE but this was not true for most counties. # add factors iowa$county_name = as.factor(iowa$county_name) iowa$county_ansi = as.factor(iowa$county_ansi) # Single Factor Models iowa_TempQuad = lm(yield ~ meanTmax + meanTmaxSq, iowa) #summary(iowa_TempQuad) iowa$m_tempSq &lt;- iowa_TempQuad$fitted.values iowa_YearQuad = lm(yield ~ year + yearSq, iowa) #summary(iowa_YearQuad) iowa$m_yearSq &lt;- iowa_YearQuad$fitted.values iowa_County = lm(yield ~ county_name, iowa) #summary(iowa_County) iowa$m_county &lt;- iowa_County$fitted.values iowa_Combined = lm(yield ~ year + yearSq + meanTmax + meanTmaxSq + county_name, iowa) #summary(iowa_Combined) iowa$m_combined &lt;- iowa_Combined$fitted.values #summary(iowa_Combined) Figure 6.9: Single Factor Models vs Actual Corn Yield in Iowa for all years 6.3.6 Geospatial trends in corn yields by county across Iowa There have been significant increases in corn yeild between 1985 &amp; 2018. This increase is observed for all counties with the biggest yields occurring in the east central are of Iowa. brks = classInt::classIntervals( 1:100, style = &#39;fixed&#39;, fixedBreaks = seq(100,250,25), intervalClosure = &quot;right&quot; ) cornEarly = cornyields %&gt;% filter(year == 1985) cornLate = cornyields %&gt;% filter(year == 2018) mapCornEarly = merge(counties, cornEarly, by.y = &quot;county_name&quot;, by.x = &quot;name&quot;, all.x=TRUE) mapCornLate = merge(counties, cornLate, by.y = &quot;county_name&quot;, by.x = &quot;name&quot;, all.x=TRUE) 6.3.6.1 Corn Yields in 1985 vs 2018 6.4 Soybeans Soybean yield in Iowa see much of the same correlations as corn. Temperature has the strongest relationship with yield, but only up to 48 bushels. After that it is the year, which shows a broad range of impacts but fewer year over year increases than corn. Finally we see that the county have a very narrow band of impact of 10 bushels per acre. An interesting artifact is there seems to be two groups of counties, those above 40 bushels, and those below 40. soyMeanTmaxQuadModel&lt;- lm(yield ~ meanTmax + meanTmaxSq, soy) soy$m_tmax_quad &lt;- soyMeanTmaxQuadModel$fitted.values soyMeanTmaxLinModel&lt;- lm(yield ~ meanTmax, soy) soy$m_tmax_lin &lt;- soyMeanTmaxLinModel$fitted.values soyYearQuadModel&lt;- lm(yield ~ year + yearSq, soy) soy$m_year_quad &lt;- soyYearQuadModel$fitted.values soyYearLinModel&lt;- lm(yield ~ year, soy) soy$m_year_lin &lt;- soyYearLinModel$fitted.values soyCountyModel&lt;- lm(yield ~ county_name, soy) soy$m_county &lt;- soyCountyModel$fitted.values soyCombinedModel&lt;- lm(yield ~ meanTmax + meanTmaxSq + year + yearSq + county_name, soy) soy$m_combined &lt;- soyCombinedModel$fitted.values Figure 6.10: Factors of Soybean Yield in Iowa 1980-2018 6.5 Corn VS Soy This map compares the Iowa corn (left) &amp; soybean (right) yield in 2018. Both legend colors are normalized to the mean. In the west, corn sees lower yields &amp; relative to soy. In the east, corn has higher relative yields to soy. 6.5.1 Relative Corn VS Soy Yield in Iowa, 2018 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
